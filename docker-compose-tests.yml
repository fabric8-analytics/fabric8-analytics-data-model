# NOTE: Containers use the generic "coreapi" prefix so they're independent of
#       the particular project name. Project specific images are always built
#       locally when using the docker-compose file.
version: "2"
services:
  broker:
    # if you're updating tag, don't forget to also update configuration
    # for kubernetes in orchestration/restart-coreapi.sh
    image: registry.centos.org/centos/rabbitmq
    container_name: coreapi-broker
    ports:
     - "5672:5672"
     - "15672:15672"
    environment:
      RABBITMQ_USER: guest
      RABBITMQ_PASS: guest
  postgres:
    image: registry.devshift.net/bayesian/coreapi-postgres
    ports:
     - "6432:5432"
    environment:
      POSTGRESQL_USER: coreapi
      POSTGRESQL_PASSWORD: coreapi
      POSTGRESQL_DATABASE: "coreapi"
    container_name: coreapi-postgres
  pgbouncer:
    image: registry.devshift.net/bayesian/coreapi-pgbouncer
    container_name: coreapi-pgbouncer
    depends_on:
     - postgres
    ports:
     - "5432:5432"
    environment:
      POSTGRESQL_USER: coreapi
      POSTGRESQL_PASSWORD: coreapi
      POSTGRESQL_DATABASE: coreapi
      POSTGRESQL_INITIAL_DATABASE: postgres

  worker-api: &worker
    image: registry.devshift.net/bayesian/cucos-worker
    restart: always
    depends_on:
     - worker-db-migrations
     - broker
     - pgbouncer
     - minio-s3
     - gremlin-http
    environment: &worker_environment
      DEPLOYMENT_PREFIX: "${USER}"
      F8A_UNCLOUDED_MODE: 'true'
      WORKER_ADMINISTRATION_REGION: api
      RABBITMQ_SERVICE_SERVICE_HOST: coreapi-broker
      F8A_SERVER_SERVICE_HOST: coreapi-server
      POSTGRESQL_USER: coreapi
      POSTGRESQL_PASSWORD: coreapi
      POSTGRESQL_DATABASE: coreapi
      PGBOUNCER_SERVICE_HOST: coreapi-pgbouncer
      # Sync data to Scality-S3
      BAYESIAN_SYNC_S3: 1
      # 0 - Bayesian runs inside RH
      # 1 - Bayesian runs in a cloud
      OPENSHIFT_DEPLOYMENT: 0
      SENTRY_DSN: ''
      # Provide credentials here if you want to run on Amazon SQS instead of RabbitMQ, don't forget to supply
      # credentials even for server
      #AWS_SQS_ACCESS_KEY_ID: ''
      #AWS_SQS_SECRET_ACCESS_KEY: ''
      #AWS_S3_ACCESS_KEY_ID: ''
      #AWS_S3_SECRET_ACCESS_KEY: ''
      # Both can be omitted, defaults to eu-west-1
      #AWS_SQS_REGION: ''
      #AWS_S3_REGION: ''
      # If no Github API token is provided, requests will be unauthenticated, i.e. limited to 60 per hour
      # Generate your token @ https://github.com/settings/tokens
      #GITHUB_TOKEN: ""
      JACCARD_THRESHOLD: 0.4
      SIMILARITY_SCORE_THRESHOLD: 0.4
      MAX_COMPANION_PACKAGES: 5
      MAX_ALTERNATE_PACKAGES: 2
      OUTLIER_THRESHOLD: 0.6
      UNKNOWN_PACKAGES_THRESHOLD: 0.3
      PGM_SERVICE_HOST: "kronos-stack-analysis.dev.rdu2c.fabric8.io"
      PGM_SERVICE_PORT: "80"
      LICENSE_SERVICE_HOST: "stack-license-stack-license.dev.rdu2c.fabric8.io"
      LICENSE_SERVICE_PORT: "80"
      BAYESIAN_GREMLIN_HTTP_SERVICE_HOST: "bayesian-gremlin-http"
      BAYESIAN_GREMLIN_HTTP_SERVICE_PORT: "8182"
      BAYESIAN_GREMLIN_HTTPINGESTION_SERVICE_HOST: "bayesian-gremlin-http"
      BAYESIAN_GREMLIN_HTTPINGESTION_SERVICE_PORT: "8182"
      BAYESIAN_DATA_IMPORTER_SERVICE_HOST: "data-model-importer"
      BAYESIAN_DATA_IMPORTER_SERVICE_PORT: "9192"
      SCANCODE_PROCESSES: "4"
      # 'no-token' value forces the API call to not use ANY token.
      # It works, but if abused, they can ban your IP.
      # So if you need to analyse big number of packages locally,
      # set this to your API Key (get it from https://libraries.io/account)
      LIBRARIES_IO_TOKEN: "no-token"
    tty: true  # yes, really -ti -d, binwalk chokes when there's no tty kept open

  worker-ingestion:
    <<: *worker
    environment:
      <<: *worker_environment
      WORKER_ADMINISTRATION_REGION: ingestion

  worker-db-migrations:
    image: registry.devshift.net/bayesian/cucos-worker
    restart: on-failure
    container_name: coreapi-worker-db-migrations
    depends_on:
     - pgbouncer
    command: /alembic/run-db-migrations.sh
    environment:
      F8A_UNCLOUDED_MODE: 'true'
      POSTGRESQL_USER: coreapi
      POSTGRESQL_PASSWORD: coreapi
      POSTGRESQL_DATABASE: coreapi
      POSTGRESQL_INITIAL_DATABASE: postgres
      PGBOUNCER_SERVICE_HOST: coreapi-pgbouncer
      WORKER_ADMINISTRATION_REGION: ingestion
      WORKER_RUN_DB_MIGRATIONS: "1"

  minio-s3:
    image: minio/minio
    command:
        - server
        - --address
        - ":33000"
        - /export
    container_name: coreapi-s3
    ports:
      - "33000:33000"
    environment:
      MINIO_ACCESS_KEY: GNV3SAHAHA3DOT99GQII
      MINIO_SECRET_KEY: ZmvMwngonaDK5ymlCd6ptaalDdJsCn3aSSxASPaZ

  dynamodb:
    image: hilverd/dynamodb
    ports:
      - "8000:8000"
      - "4567:4567"
    mem_limit: 2G
    container_name: dynamodb

  gremlin-http:
    image: registry.devshift.net/bayesian/gremlin
    entrypoint: /bin/entrypoint-local.sh
    environment:
      - REST=1
      - DEBUG_GRAPH_METRICS=0
    ports:
      - "8181:8182"
    depends_on:
      - dynamodb
    mem_limit: 2G
    container_name: bayesian-gremlin-http
    depends_on:
      - dynamodb
